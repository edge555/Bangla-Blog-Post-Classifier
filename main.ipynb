{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bangla Blog Post Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              content        tags\n",
      "1   অফিসে তেমন ব্যস্ততা নেই, \\nকেমন একটা নিঃসঙ্গ ভ...       কবিতা\n",
      "8   সুখ আমি কল্পনা করব না \\nআমার তো নেই সুখ এই প্র...       কবিতা\n",
      "10  আমাদের ফেসবুক ঠিকানা: \\nগ্রুপ: Facebook.com/gr...  আবোল তাবোল\n",
      "12  জীবনের সব দুঃখ ব্যথা আর \\nনির্যাতনার কারণ সব ত...       কবিতা\n",
      "18  এই শহরের কোন এক প্রেমিক চেয়েছিলো \\nশীতের একলা ...  আবোল তাবোল\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "df = pd.read_json('./choturmatrik.json', encoding='utf-8')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing empty contents\n",
    "df = df[df.content.str.len() != 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['গল্প', 'আবোল তাবোল', 'কবিতা', 'সমসাময়িক', 'কিছু একটা লিখতে ইচ্ছে হচ্ছে']\n"
     ]
    }
   ],
   "source": [
    "# Unique Labels\n",
    "labels = list(set(df.tags))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "গল্প                 --- 898 samples\n",
      "আবোল তাবোল           --- 447 samples\n",
      "কবিতা                --- 3184 samples\n",
      "সমসাময়িক             --- 1 samples\n",
      "কিছু একটা লিখতে ইচ্ছে হচ্ছে --- 616 samples\n"
     ]
    }
   ],
   "source": [
    "# Printing label contents\n",
    "for label in labels:\n",
    "    print( \"{:20} --- {} samples\".format( label, df[ df.tags == label ].shape[0]  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              content  tags\n",
      "1   অফিসে তেমন ব্যস্ততা নেই, \\nকেমন একটা নিঃসঙ্গ ভ...     2\n",
      "8   সুখ আমি কল্পনা করব না \\nআমার তো নেই সুখ এই প্র...     2\n",
      "10  আমাদের ফেসবুক ঠিকানা: \\nগ্রুপ: Facebook.com/gr...     1\n",
      "12  জীবনের সব দুঃখ ব্যথা আর \\nনির্যাতনার কারণ সব ত...     2\n",
      "18  এই শহরের কোন এক প্রেমিক চেয়েছিলো \\nশীতের একলা ...     1\n"
     ]
    }
   ],
   "source": [
    "# Mapping Labels to integer s\n",
    "index2label = { i: labels[i] for i in range(len(labels)) }\n",
    "label2index = { labels[i] : i for i in range(len(labels)) }\n",
    "\n",
    "# Replacing labels to integers\n",
    "df.tags = df.tags.replace(label2index)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Words that should be ignored\n",
    "STOP_WORDS = list(set(\"\"\"\n",
    "অতএব অথচ অথবা অনুযায়ী অনেক অনেকে অনেকেই অন্তত  অবধি অবশ্য অর্থাৎ অন্য অনুযায়ী অর্ধভাগে\n",
    "আগামী আগে আগেই আছে আজ আদ্যভাগে আপনার আপনি আবার আমরা আমাকে আমাদের আমার  আমি আর আরও \n",
    "ইত্যাদি ইহা \n",
    "উচিত উনি উপর উপরে উত্তর\n",
    "এ এঁদের এঁরা এই এক একই একজন একটা একটি  একবার একে এখন এখনও এখানে এখানেই এটা এসো\n",
    "এটাই এটি এত এতটাই এতে এদের এবং এবার এমন এমনি এমনকি এর এরা এলো এস এসে \n",
    "ঐ \n",
    "ও ওঁদের ওঁর ওঁরা ওই ওকে ওখানে ওদের ওর ওরা \n",
    "কখনও কত কথা কবে কয়েক  কয়েকটি করছে করছেন করতে  করবে করবেন করলে কয়েক  কয়েকটি করিয়ে করিয়া করায়\n",
    "করলেন করা করাই করায় করার করি করিতে করিয়া করিয়ে করে করেই করেছিলেন করেছে করেছেন করেন কাউকে \n",
    "কাছ কাছে কাজ কাজে কারও কারণ কি কিংবা কিছু কিছুই কিন্তু কী কে কেউ কেউই কেন কোন কোনও কোনো কেমনে কোটি\n",
    "ক্ষেত্রে খুব \n",
    "গিয়ে গিয়েছে গুলি গেছে গেল গেলে গোটা গিয়ে গিয়েছে\n",
    "চলে চান চায় চেয়ে চায় চেয়ে চার চালু চেষ্টা \n",
    "ছাড়া ছাড়াও ছিল ছিলেন ছাড়া ছাড়াও\n",
    "জন জনকে জনের জন্য জন্যে জানতে জানা জানানো জানায়  জানিয়ে  জানিয়েছে জানায় জাানিয়ে জানিয়েছে\n",
    "টি \n",
    "ঠিক \n",
    "তখন তত তথা তবু তবে তা তাঁকে তাঁদের তাঁর তাঁরা তাঁহারা তাই তাও তাকে তাতে তাদের তার তারপর তারা তারই তাহলে তাহা তাহাতে তাহার তিনই \n",
    "তিনি তিনিও তুমি তুলে তেমন তো তোমার তুই তোরা তোর তোমাদের তোদের\n",
    "থাকবে থাকবেন থাকা থাকায় থাকে থাকেন থেকে থেকেই  থেকেও থাকায়\n",
    "দিকে দিতে দিয়ে দিয়েছে দিয়েছেন দিলেন দিয়ে দু  দুটি  দুটো দেওয়া দেওয়ার দেখতে দেখা দেখে দেন দেয়  দেশের  \n",
    "দ্বারা দিয়েছে দিয়েছেন দেয় দেওয়া দেওয়ার দিন দুই\n",
    "ধরা ধরে \n",
    "নয় না নাই নাকি নাগাদ নানা নিজে নিজেই নিজেদের নিজের নিতে নিয়ে নিয়ে নেই নেওয়া নেওয়ার নয় নতুন\n",
    "পক্ষে পর পরে পরেই পরেও পর্যন্ত পাওয়া পারি পারে পারেন পেয়ে প্রতি প্রভৃতি প্রায় পাওয়া পেয়ে প্রায় পাঁচ প্রথম প্রাথমিক\n",
    "ফলে ফিরে ফের \n",
    "বছর বদলে বরং বলতে বলল বললেন বলা বলে বলেছেন বলেন  বসে বহু বা বাদে বার বিনা বিভিন্ন বিশেষ বিষয়টি বেশ ব্যবহার ব্যাপারে বক্তব্য বন বেশি\n",
    "ভাবে  ভাবেই \n",
    "মত মতো মতোই মধ্যভাগে মধ্যে মধ্যেই  মধ্যেও মনে মাত্র মাধ্যমে মানুষ মানুষের মোট মোটেই মোদের মোর \n",
    "যখন যত যতটা যথেষ্ট যদি যদিও যা যাঁর যাঁরা যাওয়া  যাওয়ার যাকে যাচ্ছে যাতে যাদের যান যাবে যায় যার  যারা যায় যিনি যে যেখানে যেতে যেন \n",
    "যেমন \n",
    "রকম রয়েছে রাখা রেখে রয়েছে \n",
    "লক্ষ \n",
    "শুধু শুরু \n",
    "সাধারণ সামনে সঙ্গে সঙ্গেও সব সবার সমস্ত সম্প্রতি সময় সহ সহিত সাথে সুতরাং সে  সেই সেখান সেখানে  সেটা সেটাই সেটাও সেটি স্পষ্ট স্বয়ং \n",
    "হইতে হইবে হইয়া হওয়া হওয়ায় হওয়ার হচ্ছে হত হতে হতেই হন হবে হবেন হয় হয়তো হয়নি হয়ে হয়েই হয়েছিল হয়েছে হাজার\n",
    "হয়েছেন হল হলে হলেই হলেও হলো হিসাবে হিসেবে হৈলে হোক হয় হয়ে হয়েছে হৈতে হইয়া  হয়েছিল হয়েছেন হয়নি হয়েই হয়তো হওয়া হওয়ার হওয়ায়\n",
    "\"\"\".split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "অফিসে তেমন ব্যস্ততা নেই, \n",
      "কেমন একটা নিঃসঙ্গ ভাব \n",
      "মনটাকে পেতে আজকে আমার \n",
      "দিয়েছে বদলে আগের স্বভাব। \n",
      "ফেলে আসা দিন গুলো ভাবাচ্ছে, \n",
      "স্মৃতিরা আমাকে অতিষ্ঠ করে \n",
      "হয়তো বা কোন প্রতিশোধ নিতে- \n",
      "চাচ্ছে, ওরাও জুলম করছে। \n",
      "হয়ত ঘোরের মধ্যে পড়ে গেছি, \n",
      "একজন তুমি বা কাল্পনিক - \n",
      "প্রেমীকাকে খুব বিনয় করছি, \n",
      "বলছি, আমায় তুমিও বোঝ না? \n",
      "কেন কাছে আসো না ভালবাস না, \n",
      "তাহলে তো আর কিছুই হবে না, \n",
      "আমার কখনো - \n",
      "বিয়েই হবে না, সুখ মিলবে না । \n",
      "হা হা হা, দারুণ মজার তাই না? \n",
      "এমন মজার সময় কাটছে \n",
      "তবুও আমার ভাল লাগছে না, \n",
      "নিজেকে বন্দী বন্দী লাগছে \n",
      "সবকিছু যেন অচেনা অজানা। \n",
      "চেনা জানা সুখ গুলো নেই আর, \n",
      "কোথায় যে সব গিয়েছে হারিয়ে \n",
      "কেউ তার খোঁজ হয়ত জানে না \n",
      "ঠিকানা কোথায় বলতে পারে না। \n",
      "যৌবনে একাকী থাকা কষ্টের, \n",
      "একারণেই কি কাজে গতি আসে? \n",
      "সবাই চেষ্টা করে তারাতারি \n",
      "সঙ্গিনী আর সফলতা পেতে। \n",
      "আমার কি তবে প্রয়োজন সেই - \n",
      "সফলতা আর সেই সঙ্গিনী? \n",
      "হয়তো বা তাই, \n",
      "একারণেই তো বন্য হয়ে যাই। \n",
      "আমার বন্যতা হরেক রকম \n",
      "কান্না হাসির , পড়ার লেখার, \n",
      "বলার , চলার, দেবার নেবার \n",
      "ঘুমের, জাগার ইত্যাদি ইত্যাদি। \n",
      "এর সবি আমি প্রকাশ করেছি \n",
      "এর সবি হল আপন স্বভাব।\n"
     ]
    }
   ],
   "source": [
    "# Sample content\n",
    "sample = df.content.iloc[0]\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "অফিসে তেমন ব্যস্ততা নেই   কেমন একটা নিঃসঙ্গ ভাব  মনটাকে পেতে আজকে আমার  দিয়েছে বদলে আগের স্বভাব   ফেলে আসা দিন গুলো ভাবাচ্ছে   স্মৃতিরা আমাকে অতিষ্ঠ করে  হয়তো বা কোন প্রতিশোধ নিতে   চাচ্ছে  ওরাও জুলম করছে   হয়ত ঘোরের মধ্যে পড়ে গেছি   একজন তুমি বা কাল্পনিক    প্রেমীকাকে খুব বিনয় করছি   বলছি  আমায় তুমিও বোঝ না   কেন কাছে আসো না ভালবাস না   তাহলে তো আর কিছুই হবে না   আমার কখনো    বিয়েই হবে না  সুখ মিলবে না    হা হা হা  দারুণ মজার তাই না   এমন মজার সময় কাটছে  তবুও আমার ভাল লাগছে না   নিজেকে বন্দী বন্দী লাগছে  সবকিছু যেন অচেনা অজানা   চেনা জানা সুখ গুলো নেই আর   কোথায় যে সব গিয়েছে হারিয়ে  কেউ তার খোঁজ হয়ত জানে না  ঠিকানা কোথায় বলতে পারে না   যৌবনে একাকী থাকা কষ্টের   একারণেই কি কাজে গতি আসে   সবাই চেষ্টা করে তারাতারি  সঙ্গিনী আর সফলতা পেতে   আমার কি তবে প্রয়োজন সেই    সফলতা আর সেই সঙ্গিনী   হয়তো বা তাই   একারণেই তো বন্য হয়ে যাই   আমার বন্যতা হরেক রকম  কান্না হাসির   পড়ার লেখার   বলার   চলার  দেবার নেবার  ঘুমের  জাগার ইত্যাদি ইত্যাদি   এর সবি আমি প্রকাশ করেছি  এর সবি হল আপন স্বভাব \n"
     ]
    }
   ],
   "source": [
    "# Punctuations and Numeric Characters to ignore\n",
    "filters = \"\"\"\n",
    "!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n?,।!‍.0123456789০১২৩৪৫৬৭৮৯\n",
    "\"\"\"\n",
    "\n",
    "# Remove all filtered characters\n",
    "translate_dict = dict((c, ' ') for c in filters)\n",
    "translate_map = str.maketrans(translate_dict)\n",
    "\n",
    "# Applied to sample content\n",
    "print(sample.translate(translate_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['অফিসে', 'তেমন', 'ব্যস্ততা', 'নেই', 'কেমন', 'একটা', 'নিঃসঙ্গ', 'ভাব', 'মনটাকে', 'পেতে', 'আজকে', 'আমার', 'দিয়েছে', 'বদলে', 'আগের', 'স্বভাব', 'ফেলে', 'আসা', 'দিন', 'গুলো', 'ভাবাচ্ছে', 'স্মৃতিরা', 'আমাকে', 'অতিষ্ঠ', 'করে', 'হয়তো', 'বা', 'কোন', 'প্রতিশোধ', 'নিতে', 'চাচ্ছে', 'ওরাও', 'জুলম', 'করছে', 'হয়ত', 'ঘোরের', 'মধ্যে', 'পড়ে', 'গেছি', 'একজন', 'তুমি', 'বা', 'কাল্পনিক', 'প্রেমীকাকে', 'খুব', 'বিনয়', 'করছি', 'বলছি', 'আমায়', 'তুমিও', 'বোঝ', 'না', 'কেন', 'কাছে', 'আসো', 'না', 'ভালবাস', 'না', 'তাহলে', 'তো', 'আর', 'কিছুই', 'হবে', 'না', 'আমার', 'কখনো', 'বিয়েই', 'হবে', 'না', 'সুখ', 'মিলবে', 'না', 'হা', 'হা', 'হা', 'দারুণ', 'মজার', 'তাই', 'না', 'এমন', 'মজার', 'সময়', 'কাটছে', 'তবুও', 'আমার', 'ভাল', 'লাগছে', 'না', 'নিজেকে', 'বন্দী', 'বন্দী', 'লাগছে', 'সবকিছু', 'যেন', 'অচেনা', 'অজানা', 'চেনা', 'জানা', 'সুখ', 'গুলো', 'নেই', 'আর', 'কোথায়', 'যে', 'সব', 'গিয়েছে', 'হারিয়ে', 'কেউ', 'তার', 'খোঁজ', 'হয়ত', 'জানে', 'না', 'ঠিকানা', 'কোথায়', 'বলতে', 'পারে', 'না', 'যৌবনে', 'একাকী', 'থাকা', 'কষ্টের', 'একারণেই', 'কি', 'কাজে', 'গতি', 'আসে', 'সবাই', 'চেষ্টা', 'করে', 'তারাতারি', 'সঙ্গিনী', 'আর', 'সফলতা', 'পেতে', 'আমার', 'কি', 'তবে', 'প্রয়োজন', 'সেই', 'সফলতা', 'আর', 'সেই', 'সঙ্গিনী', 'হয়তো', 'বা', 'তাই', 'একারণেই', 'তো', 'বন্য', 'হয়ে', 'যাই', 'আমার', 'বন্যতা', 'হরেক', 'রকম', 'কান্না', 'হাসির', 'পড়ার', 'লেখার', 'বলার', 'চলার', 'দেবার', 'নেবার', 'ঘুমের', 'জাগার', 'ইত্যাদি', 'ইত্যাদি', 'এর', 'সবি', 'আমি', 'প্রকাশ', 'করেছি', 'এর', 'সবি', 'হল', 'আপন', 'স্বভাব']\n"
     ]
    }
   ],
   "source": [
    "# Split by spaces\n",
    "words = sample.translate(translate_map).split()\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove stopwords and filtered characters\n",
    "def sentence_to_wordlist(sentence, filters=\"!\\\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n?,।!‍.'0123456789০১২৩৪৫৬৭৮৯‘\\u200c–“”…‘\"):\n",
    "    # just to be safe\n",
    "    sentence = sentence.lower()\n",
    "    translate_dict = dict((c, ' ') for c in filters)\n",
    "    translate_map = str.maketrans(translate_dict)\n",
    "    wordlist = sentence.translate(translate_map).split()\n",
    "    return list(filter(lambda x: x not in STOP_WORDS, wordlist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class for tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    def __init__(self, documents=None):\n",
    "        self.token2id = defaultdict(lambda : 0)\n",
    "        self.id2token = defaultdict(lambda : ' ')\n",
    "        # token count in a document\n",
    "        self.dfs = {}\n",
    "        self.token_collection = set()\n",
    "        self.token_counter = Counter()\n",
    "        self.documents = []\n",
    "        \n",
    "        if documents != None:\n",
    "            self.update_documents(documents)\n",
    "            \n",
    "    def update_token_dictionary(self, remove_previous=False):\n",
    "        \n",
    "        if remove_previous:\n",
    "            self.token2id = defaultdict(lambda : 0)\n",
    "            self.id2token = defaultdict(lambda : ' ')\n",
    "            self.token2id.update({' ' : 0})\n",
    "            self.id2token.update({0 : ' '})\n",
    "        \n",
    "        self.id2token.update({ idx+1: word for idx, word in enumerate(self.token_collection) })\n",
    "        self.token2id.update({ word: idx+1 for idx, word in enumerate(self.token_collection) })\n",
    "        \n",
    "            \n",
    "    \n",
    "    def update_documents(self, documents):\n",
    "        # Extending the documents\n",
    "        self.documents.extend(documents)\n",
    "        \n",
    "        for idx, document in enumerate(documents):\n",
    "            for word in document:\n",
    "                self.token_counter[word] += 1\n",
    "                self.token_collection.add(word)\n",
    "        \n",
    "        self.update_token_dictionary()\n",
    "        \n",
    "        \n",
    "    \n",
    "    # add_documents removes the previous ones\n",
    "    def add_documents(self, documents):\n",
    "        self.documents = []\n",
    "        self.token_counter = Counter()\n",
    "        self.token2id = defaultdict(lambda : 0)\n",
    "        self.id2token = defaultdict(lambda : ' ')\n",
    "        self.update_documents(documents)\n",
    "        \n",
    "    def __len__(self):\n",
    "        assert len(self.id2token) == len(self.token2id)\n",
    "        return len(self.id2token)\n",
    "    \n",
    "    def get_token_count(self, token):\n",
    "        if token not in self.token2id.keys():\n",
    "            raise ValueError(\"Token doesn't exist\")\n",
    "        return self.token_counter[token]\n",
    "    \n",
    "    \n",
    "    def reduce_vocabulary_by_frequency(self, threshold):\n",
    "        token_collection = [ tok for tok in self.token_counter if self.token_counter[tok] > threshold ]\n",
    "        self.token_collection = set(token_collection)\n",
    "        self.update_token_dictionary(remove_previous=True)\n",
    "        \n",
    "    def bow_from_saved_documents(self):\n",
    "        bow_matrix = np.zeros((len(self.documents), len(self.token_collection)))\n",
    "        \n",
    "        for i, doc in enumerate(self.documents):\n",
    "            for tok in doc:\n",
    "                bow_matrix[i, self.token2id[tok] - 1] += 1\n",
    "        \n",
    "        return bow_matrix\n",
    "    \n",
    "    def doc2bow(self, doc):\n",
    "        bow = np.zeros(len(self.token_collection) + 1)\n",
    "        \n",
    "        for tok in doc:\n",
    "            bow[v.token2id[tok]] += 1\n",
    "            \n",
    "        return bow[1:]\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        if key >= len(self.id2token):\n",
    "            raise KeyError(\"Key can't be equal or greater than total token count\")\n",
    "        return self.id2token[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5146/5146 [00:20<00:00, 251.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create documents for vocabulary class\n",
    "documents = [ sentence_to_wordlist(sent) for sent in tqdm(df.content)  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model (using Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discard tokens below this frequency threshold\n",
    "FREQ_THRESHOLD = 50\n",
    "v = Vocabulary()\n",
    "v.add_documents(documents)\n",
    "v.reduce_vocabulary_by_frequency(FREQ_THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, max_iter=100000.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train test data \n",
    "train_x = v.bow_from_saved_documents()\n",
    "train_y = np.asarray(df.tags)\n",
    "\n",
    "train_x, train_y = shuffle(train_x, train_y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size=0.33, random_state=42)\n",
    "lr = LogisticRegression(C=1e5,max_iter=1e5)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.69      0.58       297\n",
      "           1       0.25      0.24      0.25       139\n",
      "           2       0.84      0.77      0.80      1076\n",
      "           4       0.23      0.19      0.20       187\n",
      "\n",
      "    accuracy                           0.65      1699\n",
      "   macro avg       0.45      0.47      0.46      1699\n",
      "weighted avg       0.66      0.65      0.65      1699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "কবিতা\n"
     ]
    }
   ],
   "source": [
    "test_string = \"\"\"\n",
    "  এসো, এসো, এসো হে বৈশাখ\n",
    "তাপসনিশ্বাসবায়ে মুমূর্ষুরে দাও উড়ায়ে,\n",
    "বৎসরের আবর্জনা দূর হয়ে যাক\n",
    "যাক পুরাতন স্মৃতি, যাক ভুলে যাওয়া গীতি,\n",
    "অশ্রুবাষ্প সুদূরে মিলাক।\n",
    "মুছে যাক গ্লানি, ঘুচে যাক জরা,\n",
    "অগ্নিস্নানে শুচি হোক ধরা\n",
    "রসের আবেশরাশি শুষ্ক করি দাও আসি,\n",
    "আনো আনো আনো তব প্রলয়ের শাঁখ\n",
    "মায়ার কুজ্ঝটিজাল যাক দূরে যাক।\n",
    "  \"\"\"\n",
    "\n",
    "doc = sentence_to_wordlist(test_string)\n",
    "bow_of_doc = v.doc2bow(doc)\n",
    "output = lr.predict([bow_of_doc])\n",
    "print(index2label[output[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
